{
    "rfInstance": {
        "nodes": [
            {
                "width": 216,
                "height": 269,
                "id": "HUGGING_FACE_PIPELINE-160a47cc-72e8-4088-a4af-43efdc9904d6",
                "type": "AI_ML",
                "data": {
                    "id": "HUGGING_FACE_PIPELINE-160a47cc-72e8-4088-a4af-43efdc9904d6",
                    "label": "HUGGING FACE PIPELINE",
                    "func": "HUGGING_FACE_PIPELINE",
                    "type": "AI_ML",
                    "ctrls": {
                        "model": {
                            "type": "str",
                            "default": "google/vit-base-patch16-224",
                            "desc": "The model to be used for classification.\nIf not specified, Vision Transformers (i.e. 'google/vit-base-patch16-224') are used.",
                            "functionName": "HUGGING_FACE_PIPELINE",
                            "param": "model",
                            "value": "google/vit-base-patch16-224",
                            "overload": null
                        },
                        "revision": {
                            "type": "str",
                            "default": "main",
                            "desc": "The revision of the model to be used for classification.\nIf not specified, 'main' is used.",
                            "functionName": "HUGGING_FACE_PIPELINE",
                            "param": "revision",
                            "value": "main",
                            "overload": null
                        }
                    },
                    "initCtrls": {},
                    "inputs": [
                        {
                            "name": "default",
                            "id": "default",
                            "type": "Image",
                            "desc": "The input image to be classified.\nThe image must be a PIL.Image object, wrapped in a Flojoy Image object.",
                            "multiple": false
                        }
                    ],
                    "outputs": [
                        {
                            "name": "default",
                            "id": "default",
                            "type": "DataFrame",
                            "desc": "A DataFrame containing the columns 'label' (as classification label)\nand 'score' (as the confidence score).\nAll scores are between 0 and 1, and sum to 1."
                        }
                    ],
                    "path": "AI_ML/IMAGE_CLASSIFICATION/HUGGING_FACE_PIPELINE/HUGGING_FACE_PIPELINE.py",
                    "selected": false
                },
                "position": {
                    "x": -30.313706224665395,
                    "y": -244.88074424677973
                },
                "selected": false,
                "positionAbsolute": {
                    "x": -30.313706224665395,
                    "y": -244.88074424677973
                },
                "dragging": false
            },
            {
                "id": "TABLE-1ad5fe8d-779a-4538-ad48-79819fc0e52c",
                "type": "VISUALIZATION",
                "data": {
                    "id": "TABLE-1ad5fe8d-779a-4538-ad48-79819fc0e52c",
                    "label": "TABLE",
                    "func": "TABLE",
                    "type": "VISUALIZATION",
                    "ctrls": {},
                    "initCtrls": {},
                    "inputs": [
                        {
                            "name": "default",
                            "id": "default",
                            "type": "OrderedTriple|OrderedPair|DataFrame|Vector",
                            "desc": "the DataContainer to be visualized",
                            "multiple": false
                        }
                    ],
                    "outputs": [
                        {
                            "name": "default",
                            "id": "default",
                            "type": "Plotly",
                            "desc": "the DataContainer containing the Plotly Table visualization"
                        }
                    ],
                    "path": "DATA/VISUALIZATION/PLOTLY/TABLE/TABLE.py"
                },
                "position": {
                    "x": 503.72245029876274,
                    "y": -280.4889303965772
                },
                "width": 225,
                "height": 225,
                "selected": false,
                "positionAbsolute": {
                    "x": 503.72245029876274,
                    "y": -280.4889303965772
                },
                "dragging": false
            },
            {
                "id": "IMAGE-87fcc80a-189a-41f9-bacb-709702c403ba",
                "type": "VISUALIZATION",
                "data": {
                    "id": "IMAGE-87fcc80a-189a-41f9-bacb-709702c403ba",
                    "label": "IMAGE 1",
                    "func": "IMAGE",
                    "type": "VISUALIZATION",
                    "ctrls": {},
                    "initCtrls": {},
                    "inputs": [
                        {
                            "name": "default",
                            "id": "default",
                            "type": "Image|Grayscale",
                            "desc": "the DataContainer to be visualized",
                            "multiple": false
                        }
                    ],
                    "outputs": [
                        {
                            "name": "default",
                            "id": "default",
                            "type": "Plotly",
                            "desc": "the DataContainer containing the Plotly Image visualization of the input image"
                        }
                    ],
                    "path": "DATA/VISUALIZATION/PLOTLY/IMAGE/IMAGE.py"
                },
                "position": {
                    "x": -24.849481110544673,
                    "y": -570.0336919277889
                },
                "width": 225,
                "height": 225,
                "selected": false,
                "positionAbsolute": {
                    "x": -24.849481110544673,
                    "y": -570.0336919277889
                },
                "dragging": false
            },
            {
                "id": "LOCAL_FILE-4b9454b0-a919-4604-8617-b3c76b457bc2",
                "type": "LOAD",
                "data": {
                    "id": "LOCAL_FILE-4b9454b0-a919-4604-8617-b3c76b457bc2",
                    "label": "LOCAL FILE",
                    "func": "LOCAL_FILE",
                    "type": "LOAD",
                    "ctrls": {
                        "file_path": {
                            "type": "str",
                            "default": null,
                            "desc": "The path to the file to be loaded. This can be either an absolute path or\na path relative to the \"nodes\" directory.",
                            "overload": null,
                            "functionName": "LOCAL_FILE",
                            "param": "file_path",
                            "value": "AI_ML/IMAGE_CLASSIFICATION/HUGGING_FACE_PIPELINE/assets/ada_lovelace.png"
                        },
                        "file_type": {
                            "type": "select",
                            "default": "Image",
                            "options": [
                                "Image",
                                "Grayscale",
                                "JSON",
                                "CSV"
                            ],
                            "desc": "Type of file to load, default = image.\nIf both 'file_path' and 'default' are not specified when 'file_type=\"Image\"',\na default image will be loaded.\nIf the file path is not specified and the default input is not connected,\na ValueError is raised.",
                            "overload": null,
                            "functionName": "LOCAL_FILE",
                            "param": "file_type",
                            "value": "Image"
                        }
                    },
                    "initCtrls": {},
                    "inputs": [
                        {
                            "name": "default",
                            "id": "default",
                            "type": "String",
                            "desc": "If this input node is connected, the file name will be taken from\nthe output of the connected node.\nTo be used in conjunction with batch processing.",
                            "multiple": false
                        }
                    ],
                    "outputs": [
                        {
                            "name": "default",
                            "id": "default",
                            "type": "Image|DataFrame|Grayscale",
                            "desc": "Image for file_type 'image'.\nGrayscale from file_type 'Grayscale'.\nDataFrame for file_type 'json', 'csv'."
                        }
                    ],
                    "pip_dependencies": [
                        {
                            "name": "scikit-image",
                            "v": "0.21.0"
                        }
                    ],
                    "path": "ETL/LOAD/LOCAL_FILE_SYSTEM/LOCAL_FILE/LOCAL_FILE.py"
                },
                "position": {
                    "x": -711.4287930391824,
                    "y": -242.1583358771978
                },
                "width": 216,
                "height": 188,
                "selected": false,
                "positionAbsolute": {
                    "x": -711.4287930391824,
                    "y": -242.1583358771978
                },
                "dragging": false
            }
        ],
        "edges": [
            {
                "id": "LOCAL_FILE-4b9454b0-a919-4604-8617-b3c76b457bc2->IMAGE-87fcc80a-189a-41f9-bacb-709702c403ba_d7985e31-9722-4292-8d5e-7eeb84e68495",
                "source": "LOCAL_FILE-4b9454b0-a919-4604-8617-b3c76b457bc2",
                "target": "IMAGE-87fcc80a-189a-41f9-bacb-709702c403ba",
                "sourceHandle": "default",
                "targetHandle": "default",
                "data": {
                    "outputType": "Image"
                }
            },
            {
                "id": "LOCAL_FILE-4b9454b0-a919-4604-8617-b3c76b457bc2->HUGGING_FACE_PIPELINE-160a47cc-72e8-4088-a4af-43efdc9904d6_e1ff6c47-c091-4988-b733-97832436fd58",
                "source": "LOCAL_FILE-4b9454b0-a919-4604-8617-b3c76b457bc2",
                "target": "HUGGING_FACE_PIPELINE-160a47cc-72e8-4088-a4af-43efdc9904d6",
                "sourceHandle": "default",
                "targetHandle": "default",
                "data": {
                    "outputType": "Image"
                }
            },
            {
                "id": "HUGGING_FACE_PIPELINE-160a47cc-72e8-4088-a4af-43efdc9904d6->TABLE-1ad5fe8d-779a-4538-ad48-79819fc0e52c_052b81c8-2fd3-48a4-a9e8-333ef4a5c210",
                "source": "HUGGING_FACE_PIPELINE-160a47cc-72e8-4088-a4af-43efdc9904d6",
                "target": "TABLE-1ad5fe8d-779a-4538-ad48-79819fc0e52c",
                "sourceHandle": "default",
                "targetHandle": "default",
                "data": {
                    "outputType": "DataFrame"
                }
            }
        ]
    },
    "textNodes": []
}
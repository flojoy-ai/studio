{
  "name": "Image Classification",
  "rfInstance": {
    "nodes": [
      {
        "width": 216,
        "height": 269,
        "id": "HUGGING_FACE_PIPELINE-160a47cc-72e8-4088-a4af-43efdc9904d6",
        "type": "AI_ML",
        "data": {
          "id": "HUGGING_FACE_PIPELINE-160a47cc-72e8-4088-a4af-43efdc9904d6",
          "label": "HUGGING FACE PIPELINE",
          "func": "HUGGING_FACE_PIPELINE",
          "type": "AI_ML",
          "ctrls": {
            "model": {
              "type": "str",
              "default": "google/vit-base-patch16-224",
              "desc": "The model to be used for classification.\nIf not specified, Vision Transformers (i.e. 'google/vit-base-patch16-224') are used.",
              "functionName": "HUGGING_FACE_PIPELINE",
              "param": "model",
              "value": "google/vit-base-patch16-224",
              "overload": null
            },
            "revision": {
              "type": "str",
              "default": "main",
              "desc": "The revision of the model to be used for classification.\nIf not specified, 'main' is used.",
              "functionName": "HUGGING_FACE_PIPELINE",
              "param": "revision",
              "value": "main",
              "overload": null
            }
          },
          "initCtrls": {},
          "inputs": [
            {
              "name": "default",
              "id": "default",
              "type": "Image",
              "multiple": false,
              "desc": "The input image to be classified.\nThe image must be a PIL.Image object, wrapped in a Flojoy Image object."
            }
          ],
          "outputs": [
            {
              "name": "default",
              "id": "default",
              "type": "DataFrame",
              "desc": "A DataFrame containing the columns 'label' (as classification label)\nand 'score' (as the confidence score).\nAll scores are between 0 and 1, and sum to 1."
            }
          ],
          "path": "AI_ML/IMAGE_CLASSIFICATION/HUGGING_FACE_PIPELINE/HUGGING_FACE_PIPELINE.py",
          "selected": false
        },
        "position": {
          "x": -13.335978479211576,
          "y": 17.666026019335504
        },
        "selected": false,
        "positionAbsolute": {
          "x": -13.335978479211576,
          "y": 17.666026019335504
        },
        "dragging": true
      },
      {
        "id": "LOCAL_FILE-ee9c3f95-ae91-4395-9d2a-6f6d8db1a9e2",
        "type": "LOAD",
        "data": {
          "id": "LOCAL_FILE-ee9c3f95-ae91-4395-9d2a-6f6d8db1a9e2",
          "label": "LOCAL FILE",
          "func": "LOCAL_FILE",
          "type": "LOAD",
          "ctrls": {
            "file_path": {
              "type": "str",
              "default": null,
              "desc": "The path to the file to be loaded. This can be either an absolute path or\na path relative to the \"nodes\" directory.",
              "overload": null,
              "functionName": "LOCAL_FILE",
              "param": "file_path",
              "value": "./AI_ML/IMAGE_CLASSIFICATION/HUGGING_FACE_PIPELINE/assets/ada_lovelace.png"
            },
            "file_type": {
              "type": "select",
              "options": ["Image", "Grayscale", "JSON", "CSV"],
              "default": "Image",
              "desc": "Type of file to load, default = image.\nIf both 'file_path' and 'default' are not specified when 'file_type=\"Image\"',\na default image will be loaded.\nIf the file path is not specified and the default input is not connected,\na ValueError is raised.",
              "overload": null,
              "functionName": "LOCAL_FILE",
              "param": "file_type",
              "value": "Image"
            }
          },
          "initCtrls": {},
          "inputs": [
            {
              "name": "default",
              "id": "default",
              "type": "String",
              "multiple": false,
              "desc": "If this input node is connected, the file name will be taken from\nthe output of the connected node.\nTo be used in conjunction with batch processing."
            }
          ],
          "outputs": [
            {
              "name": "default",
              "id": "default",
              "type": "Image|DataFrame|Grayscale",
              "desc": "Image for file_type 'image'.\nGrayscale from file_type 'Grayscale'.\nDataFrame for file_type 'json', 'csv'."
            }
          ],
          "pip_dependencies": [
            {
              "name": "scikit-image",
              "v": "0.21.0"
            }
          ],
          "path": "ETL/LOAD/LOCAL_FILE_SYSTEM/LOCAL_FILE/LOCAL_FILE.py"
        },
        "position": {
          "x": -585.4980076607351,
          "y": -224.07541557877877
        },
        "width": 216,
        "height": 188,
        "selected": false,
        "positionAbsolute": {
          "x": -585.4980076607351,
          "y": -224.07541557877877
        },
        "dragging": true
      },
      {
        "id": "IMAGE-cd3400d6-455c-4b50-8a99-ca872bc0e712",
        "type": "VISUALIZATION",
        "data": {
          "id": "IMAGE-cd3400d6-455c-4b50-8a99-ca872bc0e712",
          "label": "IMAGE",
          "func": "IMAGE",
          "type": "VISUALIZATION",
          "ctrls": {},
          "initCtrls": {},
          "inputs": [
            {
              "name": "default",
              "id": "default",
              "type": "Image|Grayscale",
              "multiple": false,
              "desc": "the DataContainer to be visualized"
            }
          ],
          "outputs": [
            {
              "name": "default",
              "id": "default",
              "type": "Plotly",
              "desc": "the DataContainer containing the Plotly Image visualization of the input image"
            }
          ],
          "path": "DATA/VISUALIZATION/PLOTLY/IMAGE/IMAGE.py"
        },
        "position": {
          "x": -72.72302193868445,
          "y": -480.45392718213265
        },
        "width": 225,
        "height": 269,
        "selected": false,
        "positionAbsolute": {
          "x": -72.72302193868445,
          "y": -480.45392718213265
        },
        "dragging": true
      },
      {
        "id": "TABLE-8e76c738-e09b-42e8-9b89-0195a0b8ca17",
        "type": "VISUALIZATION",
        "data": {
          "id": "TABLE-8e76c738-e09b-42e8-9b89-0195a0b8ca17",
          "label": "TABLE",
          "func": "TABLE",
          "type": "VISUALIZATION",
          "ctrls": {},
          "initCtrls": {},
          "inputs": [
            {
              "name": "default",
              "id": "default",
              "type": "OrderedTriple|OrderedPair|DataFrame|Vector",
              "multiple": false,
              "desc": "the DataContainer to be visualized"
            }
          ],
          "outputs": [
            {
              "name": "default",
              "id": "default",
              "type": "Plotly",
              "desc": "the DataContainer containing the Plotly Table visualization"
            }
          ],
          "path": "DATA/VISUALIZATION/PLOTLY/TABLE/TABLE.py"
        },
        "position": {
          "x": 533.7780278492511,
          "y": -306.40156518989323
        },
        "width": 225,
        "height": 269,
        "selected": false,
        "positionAbsolute": {
          "x": 533.7780278492511,
          "y": -306.40156518989323
        },
        "dragging": true
      }
    ],
    "edges": [
      {
        "source": "LOCAL_FILE-ee9c3f95-ae91-4395-9d2a-6f6d8db1a9e2",
        "sourceHandle": "default",
        "target": "HUGGING_FACE_PIPELINE-160a47cc-72e8-4088-a4af-43efdc9904d6",
        "targetHandle": "default",
        "id": "reactflow__edge-LOCAL_FILE-ee9c3f95-ae91-4395-9d2a-6f6d8db1a9e2default-HUGGING_FACE_PIPELINE-160a47cc-72e8-4088-a4af-43efdc9904d6default"
      },
      {
        "source": "LOCAL_FILE-ee9c3f95-ae91-4395-9d2a-6f6d8db1a9e2",
        "sourceHandle": "default",
        "target": "IMAGE-cd3400d6-455c-4b50-8a99-ca872bc0e712",
        "targetHandle": "default",
        "id": "reactflow__edge-LOCAL_FILE-ee9c3f95-ae91-4395-9d2a-6f6d8db1a9e2default-IMAGE-cd3400d6-455c-4b50-8a99-ca872bc0e712default"
      },
      {
        "source": "HUGGING_FACE_PIPELINE-160a47cc-72e8-4088-a4af-43efdc9904d6",
        "sourceHandle": "default",
        "target": "TABLE-8e76c738-e09b-42e8-9b89-0195a0b8ca17",
        "targetHandle": "default",
        "id": "reactflow__edge-HUGGING_FACE_PIPELINE-160a47cc-72e8-4088-a4af-43efdc9904d6default-TABLE-8e76c738-e09b-42e8-9b89-0195a0b8ca17default"
      }
    ],
    "viewport": {
      "x": 1105.0678207150697,
      "y": 575.2550328315427,
      "zoom": 1.2199420644594634
    }
  },
  "textNodes": []
}
